}
data <- x$get()
m <- solve(data, ...)
x$setinverse(m)
m
}
megamatrix <- makeCacheMatrix(new)
cacheSolve(megamatrix)
cacheSolve(megamatrix)
new <- matrix(c(1:9), 3, 3)
megamatrix <- makeCacheMatrix(new)
cacheSolve(megamatrix)
makeCacheMatrix <- function(x = matrix()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setinverse <- function(inverse) m <<- inverse
getinverse <- function() m
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
cacheSolve <- function(x, ...) {
m <- x$getinverse()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data, ...)
x$setinverse(m)
m
}
new <- matrix(c(2:9,11), 3, 3)
megamatrix <- makeCacheMatrix(new)
cacheSolve(megamatrix)
cacheSolve(megamatrix)
new <- matrix(c(1:6,9:11), 3, 3)
new
source(cachematrix.r)
source("cachematrix.r")
source("~/R Resoursec/cachematrix.r")
source("~/R Resoursec/ProgrammingAssignment2/cachematrix.r")
source("~/R Resoursec/ProgrammingAssignment2/cachematrix.R")
source("~/R Resourses/ProgrammingAssignment2/cachematrix.R")
source("~/R Resources/ProgrammingAssignment2/cachematrix.R")
megamatrix <- makeCacheMatrix(new)
cacheSolve(megamatrix)
new
new <- matrix(c(1:7,11,17), 3, 3)
megamatrix <- makeCacheMatrix(new)
cacheSolve(megamatrix)
ncol(new)
nrow(new)
source("~/R Resources/ProgrammingAssignment2/cachematrix.R")
source("~/R Resources/ProgrammingAssignment2/cachematrix.R")
megamatrix <- makeCacheMatrix(new)
cacheSolve(megamatrix)
cacheSolve(megamatrix)
new <- matrix(c(1:7,11,19), 3, 3)
megamatrix <- makeCacheMatrix(new)
cacheSolve(megamatrix)
cacheSolve(megamatrix)
new <- matrix(c(1:6), 3, 2)
megamatrix <- makeCacheMatrix(new)
cacheSolve(megamatrix)
det(new)
new <- matrix(c(1:7,11,19), 3, 3)
det(new)
new <- matrix(c(1:9), 3, 3)
det(new)
new <- matrix(c(1:6), 3, 2)
source("~/R Resources/ProgrammingAssignment2/cachematrix.R")
megamatrix <- makeCacheMatrix(new)
source("~/R Resources/ProgrammingAssignment2/cachematrix.R")
source("~/R Resources/ProgrammingAssignment2/cachematrix.R")
megamatrix <- makeCacheMatrix(new)
cacheSolve(megamatrix)
source("~/R Resources/ProgrammingAssignment2/cachematrix.R")
megamatrix <- makeCacheMatrix(new)
cacheSolve(megamatrix)
new <- matrix(c(1:9), 3, 3)
megamatrix <- makeCacheMatrix(new)
cacheSolve(megamatrix)
source("~/R Resources/ProgrammingAssignment2/cachematrix.R")
a <- makeCacheMatrix(matrix(1:4,2))
a$get()
a$getInverse()
a$getinverse()
a$set(matrix(5:8,2))
a$get()
cacheSolve(a)
cacheSolve(a)
a$getInverse()
a$getinverse()
b = a$getInverse()
b = a$getinverse()
a$get() %*% b
set(new)
a$set(new)
a$get()
new
cacheSolve(a)
set(matrix(2:7,11,17,19,8), 3, 3)
a$set(matrix(2:7,11,17,19,8), 3, 3)
a$set(matrix(c(2:7,11,17,19,8), 3, 3)
)
a$set(matrix(c(2:7,11,17,19), 3, 3))
cacheSolve(a)
cacheSolve(a)
a$set(matrix(c(2:7,11,17,20), 3, 3))
cacheSolve(a)
cacheSolve(a)
?return
source("~/R Resources/ProgrammingAssignment2/cachematrix.R")
a$set(matrix(c(2:7,11,17,20), 3, 3))
cacheSolve(a)
fileUrl <- "https://stat.yandex-team.ru/Distribution/Special/Summaries/Desktop/ByChannel?_type=csv&_date_max_extend=1&date_min=2014-05-05+00%3A00%3A00&date_max=2014-05-05+23%3A59%3A59&date_surge=&fields=install_new&fields=hits_morda&fields=percent_morda&fields=all_hits_morda&fields=percent_serp&fields=all_hits_serp&fields=hits_morda_old&fields=percent_morda_old&fields=all_hits_morda_old&fields=hits_serp_old&fields=percent_serp_old&fields=all_hits_serp_old&max_distance=3&path=%09R%09Commercial+bundling%09&region=%D0%9A%D0%A3%D0%91%D0%A0&scale=d&sort_field=&sort_reverse=&view=&visualiser=HighCharts&_region_=TOT&rich=1&_allow_transpose=0"
download.file(fileUrl, destfile="~/Desktop/20140505.csv", method="curl")
list.files("~/Desktop")
fileUrl <- "https://stat.yandex-team.ru/Distribution/Special/Summaries/Desktop/ByChannel?type=csv&_date_max_extend=1&date_min=2014-05-05+00%3A00%3A00&date_max=2014-05-05+23%3A59%3A59&date_surge=&fields=install_new&fields=hits_morda&fields=percent_morda&fields=all_hits_morda&fields=percent_serp&fields=all_hits_serp&fields=hits_morda_old&fields=percent_morda_old&fields=all_hits_morda_old&fields=hits_serp_old&fields=percent_serp_old&fields=all_hits_serp_old&max_distance=3&path=%09R%09Commercial+bundling%09&region=%D0%9A%D0%A3%D0%91%D0%A0&scale=d&sort_field=&sort_reverse=&view=&visualiser=HighCharts&_region_=TOT&rich=1&_allow_transpose=0"
download.file(fileUrl, destfile="~/Desktop/20140505.csv", method="curl")
list.files("~/Desktop")
file <- read.csv("~/Desktop/20140505.csv")
file
?read.csv
fileUrl <- "https://stat.yandex-team.ru/Distribution/Special/Summaries/Desktop/ByChannel?type=csv&_date_max_extend=1&date_min=2014-05-05+00%3A00%3A00&date_max=2014-05-05+23%3A59%3A59&date_surge=&fields=install_new&fields=hits_morda&fields=percent_morda&fields=all_hits_morda&fields=percent_serp&fields=all_hits_serp&fields=hits_morda_old&fields=percent_morda_old&fields=all_hits_morda_old&fields=hits_serp_old&fields=percent_serp_old&fields=all_hits_serp_old&max_distance=3&path=%09R%09Commercial+bundling%09&region=%D0%9A%D0%A3%D0%91%D0%A0&scale=d&sort_field=&sort_reverse=&view=&visualiser=HighCharts&_region_=TOT&rich=1&_allow_transpose=0"
download.file(fileUrl, destfile="~/Desktop/20140505.csv", method="curl")
list.files("~/Desktop")
file <- read.csv("~/Desktop/20140505.csv", sep=";")
file
file <- read.csv("~/Desktop/20140505.csv", sep=";")
file
library(xlsx)
colindex <- 7:15
rowindex <- 18:23
excelread <- read.xlsx("~/Desktop/NGAP.xlsx",sheetIndex=1,colIndex=colindex,rowIndex=rowindex)
View(excelread)
dat <- read.xlsx("~/Desktop/NGAP.xlsx",sheetIndex=1,colIndex=colindex,rowIndex=rowindex)
sum(dat$Zip*dat$Ext,na.rm=T)
View(dat)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl, destfile="~/Desktop/restaurants.xml", method="curl")
library(XML)
install.packages("XML")
library(XML)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
?xmlTreeParse
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl, destfile="~/Desktop/restaurants.xml", method="curl")
doc <- xmlTreeParse("~/Desktop/restaurants.xml",useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
xpathSApply(rootNode,"//zipcode",xmlValue)
gold <- subset(zips, 21231)
zips <- xpathSApply(rootNode,"//zipcode",xmlValue)
gold <- subset(zips, 21231)
gold <- subset(zips, zips==21231)
gold
length(gold)
?fread
install.packages("read.table")
library("read.table")
install.packages("read.table")
install.packages("data.table")
library("read.table")
library("data.table")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile="~/Desktop/Idaho2.csv", method="curl")
?fread
DT <- fread("~/Desktop/Idaho2.csv")
View(DT)
tapply(DT$pwgtp15,DT$SEX,mean)
DT[,mean(pwgtp15),by=SEX]
mean(DT$pwgtp15,by=DT$SEX)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
sapply(split(DT$pwgtp15,DT$SEX),mean)
?mean
tapply(DT$pwgtp15,DT$SEX,mean)
DT[,mean(pwgtp15),by=SEX]
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
sapply(split(DT$pwgtp15,DT$SEX),mean)
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
trial_size <- 200
collected_results <- numeric(trial_size)
for (i in 1:trial_size){
single_function_time <- system.time(tapply(DT$pwgtp15,DT$SEX,mean))
collected_results[i] <- single_function_time[1]
}
print(mean(collected_results))
trial_size <- 200
collected_results <- numeric(trial_size)
for (i in 1:trial_size){
single_function_time <- system.time(tapply(DT$pwgtp15,DT$SEX,mean))
collected_results[i] <- single_function_time[1]
}
print(mean(collected_results))
collected_results <- numeric(trial_size)
for (i in 1:trial_size){
single_function_time <- system.time(DT[,mean(pwgtp15),by=SEX])
collected_results[i] <- single_function_time[1]
}
print(mean(collected_results))
collected_results <- numeric(trial_size)
for (i in 1:trial_size){
single_function_time <- system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
collected_results[i] <- single_function_time[1]
}
print(mean(collected_results))
collected_results <- numeric(trial_size)
for (i in 1:trial_size){
single_function_time <- system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
collected_results[i] <- single_function_time[1]
}
print(mean(collected_results))
trial_size <- 500
collected_results <- numeric(trial_size)
for (i in 1:trial_size){
single_function_time <- system.time(tapply(DT$pwgtp15,DT$SEX,mean))
collected_results[i] <- single_function_time[1]
}
print(mean(collected_results))
collected_results <- numeric(trial_size)
for (i in 1:trial_size){
single_function_time <- system.time(DT[,mean(pwgtp15),by=SEX])
collected_results[i] <- single_function_time[1]
}
print(mean(collected_results))
collected_results <- numeric(trial_size)
for (i in 1:trial_size){
single_function_time <- system.time({mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)})
collected_results[i] <- single_function_time[1]
}
print(mean(collected_results))
collected_results <- numeric(trial_size)
for (i in 1:trial_size){
single_function_time <- system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
collected_results[i] <- single_function_time[1]
}
print(mean(collected_results))
install.packages("RMySQL")
X_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/X_train.txt", sep=" ")
X_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/X_train.txt", header = FALSE, sep="\t")
View(X_train)
View(X_train)
X_train <- read.csv("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/X_train.txt", header = FALSE, sep="\t")
X_train <- read.csv("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/X_train.txt", header = FALSE, sep=" ")
View(X_train)
X_train <- read.csv("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/X_train.txt", header = FALSE, sep="")
View(X_train)
X_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/X_train.txt", header = FALSE, sep="")
subject_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/subject_train.txt")
View(subject_train)
subject_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/subject_train.txt", col.names=subject)
View(subject_train)
subject_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/subject_train.txt", col.names="subject")
View(subject_train)
y_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/y_train.txt", col.names="act_label")
?cbind
train <- cbind(subject_train, y_train, X_train)
View(train)
activity_labels <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/activity_labels.txt", col.names=c("act_label","act_name"))
View(activity_labels)
activity <- merge(y_train,activity_labels)
View(activity)
train <- cbind(subject_train, activity, X_train)
View(train)
features <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/features.txt")
View(features)
names(X_train) <- features[,1]
View(X_train)
names(X_train) <- features[,2]
View(X_train)
activity <- merge(y_train,activity_labels)
train <- cbind(subject_train, activity, X_train)
View(train)
train <- cbind(subject_train, activity[,2], X_train)
View(train)
X_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/X_train.txt", sep="")
X_test <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/test/X_test.txt", sep="")
X <- rbind(X_train, X_test)
subject_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/subject_train.txt", col.names="subject")
subject_test <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/test/subject_test.txt", col.names="subject")
subjct <- rbind(subject_train, subject_test)
y_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/y_train.txt", col.names="act_label")
y_test <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/test/y_test.txt", col.names="act_label")
Y <- rbind(Y_train, Y_test)
Y <- rbind(y_train, y_test)
subject <- rbind(subject_train, subject_test)
combined <- cbind(subject, activity[,2], X)
names(X) <- features[,2]
activity <- merge(Y,activity_labels)
combined <- cbind(subject, activity[,2], X)
View(combined)
featurevector <- features[,2]
featurevector[grepl("mean")]
featurevector[grepl("mean", featurevector)]
grepl("mean", featurevector)
grepl("(mean|std)", featurevector)
featurevector[grepl("(mean|std)", featurevector)]
featurevector[grepl("(mean\(\)|std\(\))", featurevector)]
featurevector[grepl("(mean\\(\\)|std\\(\\))", featurevector)]
test <- X[,featurevector]
View(test)
test <- X[,index]
index <- grepl("(mean\\(\\)|std\\(\\))", featurevector)
test <- X[,index]
View(test)
#Check whether the directory exists. If not - create
if(!file.exists("./data")){dir.create("./data")}
#Download data file from the web
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "~/R Resources/wearable_devices/data/zipped_data.zip", method = "curl")
#Unzip the downloaded file to the working directory
unzip("~/R Resources/wearable_devices/data/zipped_data.zip", exdir="~/R Resources/wearable_devices/data")
#read main data
X_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/X_train.txt", sep="")
X_test <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/test/X_test.txt", sep="")
X <- rbind(X_train, X_test)
#read subjects
subject_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/subject_train.txt", col.names="subject")
subject_test <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/test/subject_test.txt", col.names="subject")
subject <- rbind(subject_train, subject_test)
#read activities
y_train <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/train/y_train.txt", col.names="act_label")
y_test <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/test/y_test.txt", col.names="act_label")
Y <- rbind(y_train, y_test)
#read dictionaries
activity_labels <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/activity_labels.txt", col.names=c("act_label","act_name"))
features <- read.table("~/R Resources/wearable_devices/data/UCI HAR Dataset/features.txt")
#create a vector of names for X, apply these names
activity <- merge(Y,activity_labels)
featurevector <- features[,2]
names(X) <- features[,2]
#select only names containing mean() or std()
index <- grepl("(mean\\(\\)|std\\(\\))", featurevector)
X_short <- X[,index] #select only the columns with mean and std
#join all
combined <- cbind(subject, activity[,2], X_Short)
combined <- cbind(subject, activity[,2], X_short)
View(combined)
?image
library(plyr)
m20121115 <- read.table("~/Desktop/49792_models_20121115.csv", sep=";", col.names = c("model","data1"), fileEncoding="UTF-16LE")
m20121215 <- read.table("~/Desktop/49792_models_20121215.csv", sep=";", skip=6, col.names = c("model","data2"), fileEncoding="UTF-16LE")
m20130115 <- read.table("~/Desktop/49792_models_20130115.csv", sep=";", skip=6, col.names = c("model","data3"), fileEncoding="UTF-16LE")
m20130215 <- read.table("~/Desktop/49792_models_20130215.csv", sep=";", skip=6, col.names = c("model","data4"), fileEncoding="UTF-16LE")
m20130315 <- read.table("~/Desktop/49792_models_20130315.csv", sep=";", skip=6, col.names = c("model","data5"), fileEncoding="UTF-16LE")
m20130415 <- read.table("~/Desktop/49792_models_20130415.csv", sep=";", skip=6, col.names = c("model","data6"), fileEncoding="UTF-16LE")
m20130515 <- read.table("~/Desktop/49792_models_20130515.csv", sep=";", skip=6, col.names = c("model","data7"), fileEncoding="UTF-16LE")
m20130615 <- read.table("~/Desktop/49792_models_20130615.csv", sep=";", skip=6, col.names = c("model","data8"), fileEncoding="UTF-16LE")
m20130715 <- read.table("~/Desktop/49792_models_20130715.csv", sep=";", skip=6, col.names = c("model","data9"), fileEncoding="UTF-16LE")
m20130815 <- read.table("~/Desktop/49792_models_20130815.csv", sep=";", skip=6, col.names = c("model","data10"), fileEncoding="UTF-16LE")
m20130915 <- read.table("~/Desktop/49792_models_20130915.csv", sep=";", skip=6, col.names = c("model","data11"), fileEncoding="UTF-16LE")
m20131015 <- read.table("~/Desktop/49792_models_20131015.csv", sep=";", skip=6, col.names = c("model","data12"), fileEncoding="UTF-16LE")
m20131115 <- read.table("~/Desktop/49792_models_20131115.csv", sep=";", skip=6, col.names = c("model","data13"), fileEncoding="UTF-16LE")
m20131215 <- read.table("~/Desktop/49792_models_20131215.csv", sep=";", skip=6, col.names = c("model","data14"), fileEncoding="UTF-16LE")
dfList = list(m20121115,m20121215,m20130115,m20130215,m20130315,m20130415,m20130515,m20130615,m20130715,m20130815,m20130915,m20131015,m20131115,m20131215)
merged <- join_all(dfList)
write.table(merged, file = "~/Desktop/merged.csv", quote=FALSE, sep=";",  row.names = FALSE, na="0")
library(plyr)
m20121115 <- read.table("~/Desktop/49792_models_20121115.csv", sep=";", skip=6, col.names = c("model","data1"), fileEncoding="UTF-16LE")
m20121215 <- read.table("~/Desktop/49792_models_20121215.csv", sep=";", skip=6, col.names = c("model","data2"), fileEncoding="UTF-16LE")
m20130115 <- read.table("~/Desktop/49792_models_20130115.csv", sep=";", skip=6, col.names = c("model","data3"), fileEncoding="UTF-16LE")
m20130215 <- read.table("~/Desktop/49792_models_20130215.csv", sep=";", skip=6, col.names = c("model","data4"), fileEncoding="UTF-16LE")
m20130315 <- read.table("~/Desktop/49792_models_20130315.csv", sep=";", skip=6, col.names = c("model","data5"), fileEncoding="UTF-16LE")
m20130415 <- read.table("~/Desktop/49792_models_20130415.csv", sep=";", skip=6, col.names = c("model","data6"), fileEncoding="UTF-16LE")
m20130515 <- read.table("~/Desktop/49792_models_20130515.csv", sep=";", skip=6, col.names = c("model","data7"), fileEncoding="UTF-16LE")
m20130615 <- read.table("~/Desktop/49792_models_20130615.csv", sep=";", skip=6, col.names = c("model","data8"), fileEncoding="UTF-16LE")
m20130715 <- read.table("~/Desktop/49792_models_20130715.csv", sep=";", skip=6, col.names = c("model","data9"), fileEncoding="UTF-16LE")
m20130815 <- read.table("~/Desktop/49792_models_20130815.csv", sep=";", skip=6, col.names = c("model","data10"), fileEncoding="UTF-16LE")
m20130915 <- read.table("~/Desktop/49792_models_20130915.csv", sep=";", skip=6, col.names = c("model","data11"), fileEncoding="UTF-16LE")
m20131015 <- read.table("~/Desktop/49792_models_20131015.csv", sep=";", skip=6, col.names = c("model","data12"), fileEncoding="UTF-16LE")
m20131115 <- read.table("~/Desktop/49792_models_20131115.csv", sep=";", skip=6, col.names = c("model","data13"), fileEncoding="UTF-16LE")
m20131215 <- read.table("~/Desktop/49792_models_20131215.csv", sep=";", skip=6, col.names = c("model","data14"), fileEncoding="UTF-16LE")
dfList = list(m20121115,m20121215,m20130115,m20130215,m20130315,m20130415,m20130515,m20130615,m20130715,m20130815,m20130915,m20131015,m20131115,m20131215)
merged <- join_all(dfList)
write.table(merged, file = "~/Desktop/merged.csv", quote=FALSE, sep=";",  row.names = FALSE, na="0")
View(`m20131015`)
View(`m20130915`)
View(`m20130715`)
View(merged)
?join_all
merged <- join_all(dfList, type=full)
merged <- join_all(dfList, type="full")
View(merged)
library(plyr)
library(psych)
library(lattice)
w120t <- read.csv("~/Desktop/w120triple.csv", sep=";")
w123t <- read.csv("~/Desktop/w123triple.csv", sep=";")
w124t <- read.csv("~/Desktop/w124triple.csv", sep=";")
weekList = list(w120t,w123t,w124t)
View(`w120t`)
View(`w123t`)
View(`w124t`)
triple <- join_all(weekList, type="inner")
View(triple)
shortall <- triple[,c(1,3,5,7)]
shortall_cons <- ddply(shortall,"fuid",numcolwise(sum))
shortall_cons$change = shortall_cons$hits124/shortall_cons$hits120-1
describe(shortall_cons)
atLeastOnce <- subset(triple, ( browser120!="YandexBrowser" & (browser123=="YandexBrowser" | browser124=="YandexBrowser") ) )
fuidsaffected <- atLeastOnce[,1]
df <- data.frame(unique(fuidsaffected))
names(df) <- "fuid"
fuids_act <- merge(triple, df)
fuidhit <- fuids_act[,c(1,3,5,7)]
allbros <- ddply(fuidhit,"fuid",numcolwise(sum))
allbros$actgroups = cut(allbros$hits120, breaks=quantile(allbros$hits120))
allbros$change = allbros$hits124/allbros$hits120-1
describe(allbros)
describeBy(allbros, group=allbros$actgroups)
describeBy(allbros, group=allbros$actgroups)
View(combined)
?ddply
combined_aggr <- ddply(combined, c("subject","activity[, 2]"), numcolwise(average))
combined_aggr <- ddply(combined, c("subject","activity[, 2]"), numcolwise(sum))
View(combined_aggr)
write.table(combined, file = "~/Desktop/combo.csv", quote=FALSE, sep=";",  row.names = FALSE, na="0")
View(combined_aggr)
?numcolwise
combined_aggr <- ddply(combined, c("subject","activity[, 2]"), numcolwise(mean))
View(combined_aggr)
View(activity)
View(activity_labels)
View(allbros)
View(atLeastOnce)
View(combined)
write.table(combined_aggr, file = "~/Desktop/combo.csv", quote=FALSE, sep=";",  row.names = FALSE, na="0")
?gsub
combined_aggr[,1]
combined_aggr[1,]
names(combined_aggr)
gsub("()","",names(combined_aggr)
)
gsub("()","",names(combined_aggr))
gsub("\\(\\)","", names(combined_aggr))
gsub("-","", names(combined_aggr))
names(combined_aggr) <- gsub("\\(\\)","", names(combined_aggr))
names(combined_aggr) <- gsub("-","", names(combined_aggr))
View(combined_aggr)
combined_aggr <- ddply(combined, c("subject","activity[, 2]"), numcolwise(mean))
names(combined_aggr) <- gsub("\\(\\)","", names(combined_aggr))
names(combined_aggr) <- gsub("-","", names(combined_aggr))
names(combined_aggr) <- gsub("std","Std", names(combined_aggr))
names(combined_aggr) <- gsub("mean","Mean", names(combined_aggr))
View(combined_aggr)
names(combined_aggr)[,2]
names(combined_aggr)[2]
names(combined_aggr)[2] <- "activity"
View(combined_aggr)
getwd()
setwd("~/R Resources/WearableDevices")
getwd()
#Check whether the directory for the data exists. If not - create.
if(!file.exists("./data")){dir.create("./data")}
#Download data file from the web
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "~/R Resources/wearable_devices/data/zipped_data.zip", method = "curl")
#Unzip the downloaded file to the working directory
unzip("./data/zipped_data.zip", exdir="./data")
#Check whether the directory for the data exists. If not - create.
if(!file.exists("./data")){dir.create("./data")}
#Download data file from the web
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "./zipped_data.zip", method = "curl")
#Unzip the downloaded file to the working directory
unzip("./data/zipped_data.zip", exdir="./data")
#Download data file from the web
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "./zipped_data.zip", method = "curl")
#Unzip the downloaded file to the working directory
unzip("./zipped_data.zip", exdir="./")
